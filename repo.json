{
  "src/bin/cmd.mjs": "#!/usr/bin/env node\n\nimport { $, which, fs } from \"zx\";\nimport { config } from \"dotenv\";\nimport { Command } from \"commander\";\nimport commandTerraform from \"../lib/command-terraform.mjs\";\nimport commandCustom from \"../lib/command-custom.mjs\";\nimport commandVault from \"../lib/command-vault.mjs\";\nimport commandAction from \"../lib/command-action.mjs\";\nimport commandGithub from \"../lib/command-github.mjs\";\nimport commandSkaffold from \"../lib/command-skaffold.mjs\";\nimport commandHasura from \"../lib/command-hasura.mjs\";\nimport commandCluster from \"../lib/command-cluster.mjs\";\nimport commandDb from \"../lib/command-db.mjs\";\nimport commandUtils from \"../lib/command-utils.mjs\";\nimport commandDocker from \"../lib/command-docker.mjs\";\nimport commandVercel from \"../lib/command-vercel.mjs\";\nimport commandLib from \"../lib/command-lib.mjs\";\nimport commandMachine from \"../lib/command-machine.mjs\";\nimport commandGhost from \"../lib/command-ghost.mjs\";\n\n////////////////////////////////////////////////////////////////////////////////\n// CONST\n////////////////////////////////////////////////////////////////////////////////\n\nconst SRC = process.env.SRC;\n\n////////////////////////////////////////////////////////////////////////////////\n// CONST\n////////////////////////////////////////////////////////////////////////////////\n\nconst currentPath = process.cwd();\n\n////////////////////////////////////////////////////////////////////////////////\n// DOTENV\n////////////////////////////////////////////////////////////////////////////////\n\nconfig({ path: `${SRC}/.env` });\nconfig({ path: `${currentPath}/.env` });\n\n////////////////////////////////////////////////////////////////////////////////\n// STARTING PROGRAM\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\nconst program = new Command();\n\nprogram.exitOverride();\n\nprogram.name(\"run\");\n\n////////////////////////////////////////////////////////////////////////////////\n// GIT COMMAND\n////////////////////////////////////////////////////////////////////////////////\n\nawait commandMachine(program);\nawait commandTerraform(program);\nawait commandCustom(program);\nawait commandVault(program);\nawait commandAction(program);\nawait commandGithub(program);\nawait commandSkaffold(program);\nawait commandHasura(program);\nawait commandCluster(program);\nawait commandDb(program);\nawait commandUtils(program);\nawait commandDocker(program);\nawait commandVercel(program);\nawait commandLib(program);\nawait commandGhost(program);\n\n////////////////////////////////////////////////////////////////////////////////\n// GIT COMMAND\n////////////////////////////////////////////////////////////////////////////////\n\ntry {\n  program.parse(process.argv);\n} catch (err) {\n  const { exitCode, name, code, message } = err;\n\n  if (!message.includes(\"outputHelp\")) {\n    console.error(\"something went wrong\");\n  }\n}\n",
  "src/lib/command-action.mjs": "import { $, which, sleep, cd, fs } from 'zx';\nimport core from '@actions/core';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from '../utils/divers.mjs';\n\nimport { envDevcontainer } from '../main.mjs';\nimport path from 'path';\nimport yaml from 'js-yaml';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\nconst LOCALHOST_SRC =\n  process.env.CODESPACES === 'true'\n    ? process.env.SRC\n    : process.env.LOCALHOST_SRC;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// ACTION DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nconst actionConfigDefault = {};\n\n////////////////////////////////////////////////////////////////////////////////\n// ACT DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nconst actArgmentsDefault = [\n  {\n    name: '--platform',\n    value: `ubuntu-latest=catthehacker/ubuntu:act-latest`,\n  },\n  { name: '--defaultbranch', value: 'main' },\n  { name: '--directory', value: LOCALHOST_SRC },\n  { name: '--bind', value: `` },\n  { name: '--use-gitignore', value: '' },\n\n  // {\n  //   name: '--workflows',\n  //   value: `${LOCALHOST_SRC}/.github/workflows`,\n  // },\n  {\n    name: '--secret',\n    value: `VAULT_ROOT_TOKEN=${process.env.VAULT_ROOT_TOKEN}`,\n  },\n  { name: '--secret', value: `VAULT_ADDR=${process.env.VAULT_ADDR}` },\n  {\n    name: '--secret',\n    value: `GCP_PROJECT_NAME=${process.env.GCP_PROJECT_NAME}`,\n  },\n  {\n    name: '--secret',\n    value: `actions_token=${process.env.GH_TOKEN}`,\n  },\n];\n\n////////////////////////////////////////////////////////////////////////////////\n// UTIL: CONVERT ACT ARGUMENTS ARRAY TO STRING\n////////////////////////////////////////////////////////////////////////////////\n\nasync function actArgmentsToOneDimensionArray(actArgmentsConstants) {\n  let actArgmentsArray = [];\n  for (let i = 0; i < actArgmentsConstants.length; i++) {\n    actArgmentsArray.push(actArgmentsConstants[i].name);\n    if (actArgmentsConstants[i].value !== '') {\n      actArgmentsArray.push(actArgmentsConstants[i].value);\n    }\n  }\n  return actArgmentsArray;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN REMOTE ACTIOn\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function actionRunRemote(workflow, options) {\n  $.verbose = true;\n\n  const { watch, input, branch } = options;\n\n  let refBranch = branch ? branch : 'main';\n\n  let inputsArguments = [];\n\n  if (input !== undefined) {\n    for (let inputArg in input) {\n      inputsArguments.push('-f');\n      inputsArguments.push(input[inputArg]);\n    }\n  }\n\n  try {\n    await $`gh workflow run ${workflow} --ref ${refBranch} ${inputsArguments}`;\n  } catch (error) {\n    console.log(error.stderr);\n  }\n\n  if (watch) {\n    $.verbose = false;\n\n    await sleep(5000);\n\n    const runId =\n      await $`gh run list --limit 1 | sed -En '1p' | awk '{ print $(NF - 2) }'`;\n\n    $.verbose = true;\n\n    await $`gh run watch ${runId}`;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN ACTION LOCALLY WITH ACT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function actionRunLocal(target, actArguments, event, custom) {\n  const actArgmentsCombined = [...actArgmentsDefault, ...actArguments];\n\n  const actArgmentsArray = await actArgmentsToOneDimensionArray(\n    actArgmentsCombined\n  );\n\n  //  read all files in /github/workflows\n\n  // remove /tmo/.github if it exists\n\n  let workflowsPath = LOCALHOST_SRC + '/.github/workflows';\n\n  if (custom == true) {\n    actArgmentsArray[0] = '--platform';\n    actArgmentsArray[1] = `ubuntu-latest=ghcr.io/ghostmind-dev/act-base:latest`;\n\n    await $`rm -rf /tmp/.github`;\n\n    await $`cp -r .github/ /tmp/.github`;\n\n    const workflowsDir = '/tmp/.github/workflows';\n    const workflowFiles = await fs.readdir(workflowsDir);\n\n    for (const file of workflowFiles) {\n      const filePath = path.join(workflowsDir, file);\n      // Check if it's a .yml or .yaml file before processing\n      if (path.extname(file) === '.yml' || path.extname(file) === '.yaml') {\n        const content = await fs.readFile(filePath, 'utf8');\n        const parsedYaml = yaml.load(content);\n\n        // Modify each job in the workflow\n        for (const jobKey in parsedYaml.jobs) {\n          if (parsedYaml.jobs[jobKey].container) {\n            delete parsedYaml.jobs[jobKey].container;\n          }\n        }\n\n        // Write the modified content back to /tmp/.github/workflows/\n        const modifiedContent = yaml.dump(parsedYaml);\n        await fs.writeFile(filePath, modifiedContent);\n      }\n    }\n\n    $.verbose = true;\n\n    workflowsPath = '/tmp/.github/workflows';\n  }\n\n  $.verbose = true;\n\n  actArgmentsArray.push('--workflows');\n  actArgmentsArray.push(workflowsPath);\n\n  if (event === undefined) {\n    actArgmentsArray.push('--job');\n    actArgmentsArray.push(target);\n\n    await $`act ${actArgmentsArray}`;\n  } else {\n    actArgmentsArray.push('--workflows');\n    actArgmentsArray.push(`${workflowsPath}/${target}.yaml`);\n\n    if (event === 'push') {\n      actArgmentsArray.push('--eventpath');\n    }\n    await $`act ${event} ${actArgmentsArray}`;\n  }\n}\n\nexport async function actionRunLocalEntry(target, options) {\n  const ENV = process.env.ENV;\n  const { live, input, reuse, secure, event, push, custom } = options;\n\n  let inputsArguments = {};\n\n  if (input !== undefined) {\n    for (let inputArg in input) {\n      // split input argument into array with = as separator\n      let inputArgArray = input[inputArg].split('=');\n      // add input argument to inputsArguments object\n      inputsArguments[inputArgArray[0]] = inputArgArray[1];\n    }\n  }\n\n  fs.writeJsonSync('/tmp/inputs.json', {\n    inputs: {\n      LIVE: live ? 'true' : 'false',\n      LOCAL: 'true',\n      ...inputsArguments,\n    },\n  });\n  let actArgments = [\n    // { name: '--env', value: `ENV=${ENV}` },\n    { name: '--eventpath', value: '/tmp/inputs.json' },\n  ];\n  if (reuse === true) {\n    actArgments.push({ name: '--reuse', value: '' });\n  }\n\n  if (event === 'push') {\n    const eventFile = await fs.readFile(\n      `${LOCALHOST_SRC}/.github/mocking/push.json`,\n      'utf8'\n    );\n\n    // this push has 3 properties: ref, before, after\n    // add these properties to the /tmp/inputs.json file\n\n    const currentInputs = JSON.parse(\n      fs.readFileSync('/tmp/inputs.json', 'utf8')\n    );\n    const eventFileJson = JSON.parse(eventFile);\n\n    fs.writeJsonSync('/tmp/inputs.json', {\n      ...eventFileJson,\n      ...currentInputs,\n    });\n  }\n  if (!secure) {\n    actArgments.push({ name: '--insecure-secrets', value: '' });\n  }\n  await actionRunLocal(target, actArgments, event, custom);\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// SET SECRETS IN ACTION STEPS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function actionSecretsSet() {\n  $.verbose = true;\n\n  cd(currentPath);\n\n  await $`run vault kv export`;\n\n  // const envContents = await $`grep -v '^#' .env | xargs`;\n  // const envContentsArray = `${envContents}`.split(' ');\n\n  const gitEnvPathRaw = await $`echo $GITHUB_ENV`;\n\n  const gitEnvPath = `${gitEnvPathRaw}`.replace(/(\\r\\n|\\n|\\r)/gm, '');\n\n  const data = fs.readFileSync(path.resolve('.env'), 'utf8');\n  const lines = data.split('\\n');\n\n  for (const line of lines) {\n    if (!line.startsWith('#') && line.includes('=')) {\n      const [secretName, ...valueParts] = line.split('=');\n      const secretValueRaw = valueParts.join('=');\n\n      core.setSecret(secretValueRaw);\n      core.setOutput(secretName, secretValueRaw);\n\n      await $`echo ${secretName}=${secretValueRaw} >> ${gitEnvPath}`;\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// SET ENVIRONMENT NAME IN ACTION STEPS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function actionEnvSet() {\n  const environement = await envDevcontainer();\n\n  const gitEnvPathRaw = await $`echo $GITHUB_ENV`;\n\n  const gitEnvPath = `${gitEnvPathRaw}`.replace(/(\\r\\n|\\n|\\r)/gm, '');\n\n  core.setSecret(environement);\n  core.setOutput('ENV', environement);\n\n  await $`echo ENV=${environement} >> ${gitEnvPath}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function act(program) {\n  const act = program.command('action');\n  act.description('run a github action');\n\n  const actLocal = act.command('local');\n  const actRemote = act.command('remote');\n  const actSecrets = act.command('secrets');\n  const actEnv = act.command('env');\n\n  actLocal\n    .description('run local action with at')\n    .argument('[target]', 'workflow or job name')\n    .option('--live', 'run live version on run')\n    .option('--push', 'simulate push event')\n    .option('--no-reuse', 'do not reuse container state')\n    .option('--no-secure', \"show secrets in logs (don't use in production)\")\n    .option('--custom', 'custom act container')\n    .option('-i, --input [inputs...]', 'action inputs')\n    .option('--event <string>\", \" trigger event (ex: workflow_run')\n    .action(actionRunLocalEntry);\n\n  actRemote\n    .description('run local action with at')\n    .argument('[workflow]', 'workflow name')\n    .option('--watch', 'watch for changes')\n    .option('-i, --input [inputs...]', 'action inputs')\n    .option('--branch <ref>', 'branch to run workflow on')\n    .action(actionRunRemote);\n\n  actSecrets\n    .command('set')\n    .action(actionSecretsSet)\n    .description('set secrets for all the next action steps');\n\n  actEnv\n    .command('set')\n    .action(actionEnvSet)\n    .description('set environment variables for all the next action steps');\n}\n",
  "src/lib/command-cluster.mjs": "import { $, sleep, cd, fs } from 'zx';\nimport { config } from 'dotenv';\nimport {\n  detectScriptsDirectory,\n  getDirectories,\n  verifyIfMetaJsonExists,\n  withMetaMatching,\n} from '../utils/divers.mjs';\nimport { vaultKvCertsToVault, vaultKvCertsToLocal } from './command-vault.mjs';\nimport { actionRunLocal } from './command-action.mjs';\n\nimport _ from 'lodash';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\nconst SRC = process.env.SRC;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CHECK IF POD IF READY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function verifyIfPodReady(app, namespace) {\n  const CLUSTER_NAME = process.env.CLUSTER_NAME;\n\n  $.verbose = false;\n\n  await $`run cluster connect ${CLUSTER_NAME}`;\n\n  // to test this funciton, trigger this command\n  // kubectl scale --replicas=0 deployment/\n  // kubectl scale --replicas=1 deployment/\n\n  let checkPodStatus =\n    await $`kubectl get pods -l app=${app} -n ${namespace} -o 'jsonpath={..status.conditions[?(@.type==\"Ready\")].status}'`;\n\n  while (`${checkPodStatus}`.includes('Trues')) {\n    console.log(`waiting for ${app} pod to be ready`);\n    await sleep(5000);\n    checkPodStatus =\n      await $`kubectl get pods -l app=${app} -n ${namespace} -o 'jsonpath={..status.conditions[?(@.type==\"Ready\")].status}'`;\n  }\n\n  return;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// VERIFY IF CLUSTER RELATED DIRECTORY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function verifyClusterDirectory() {\n  const metaConfig = await fs.readJsonSync('meta.json');\n  let { type } = metaConfig;\n  if (type === 'cluster' || type === 'pod') {\n    if (type === 'pod') {\n      config({ path: `../../.env` });\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CONNECT TO CLUSTER\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function connectToCluster() {\n  const ENV = process.env.ENV;\n  const CLUSTER_PROJECT = process.env.RUN_CLUSTER_PROJECT;\n  const CLUSTER_ZONE = process.env.RUN_CLUSTER_ZONE;\n  $.verbose = true;\n\n  let environment;\n\n  if (ENV === 'prod') {\n    environment = 'prod';\n  } else {\n    environment = 'dev';\n  }\n\n  try {\n    await $`gcloud container clusters get-credentials core-${environment} --project ${CLUSTER_PROJECT} --zone ${CLUSTER_ZONE}`;\n    return { status: 'success', message: 'connected to cluster' };\n  } catch (e) {\n    let { stderr } = e;\n    // if sterr contains 404\n    if (stderr.includes('404')) {\n      return { status: 'error', message: 'cluster not found' };\n    }\n    return { status: 'error', message: 'unknown error' };\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// EXPORT SSL CERTIFICATES ALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function exportCertificatesAll() {\n  const matchingDirectories = await withMetaMatching({\n    property: 'cluster.tls',\n    value: true,\n  });\n\n  for (let matchDirectory of matchingDirectories) {\n    const { config: metaConfig, directory } = matchDirectory;\n\n    const { cluster, name } = metaConfig;\n\n    const { namespace, app, tls } = cluster;\n\n    cd(directory);\n\n    config({ path: '.env', override: true });\n\n    const NAMESPACE = process.env.NAMESPACE;\n\n    $.verbose = true;\n\n    const certificatJsonRaw =\n      await $`kubectl get secret certificat-${app}-${name} -n ${NAMESPACE} -o json`;\n\n    await vaultKvCertsToVault(certificatJsonRaw.stdout, directory);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// EXPORT CERTIFICATS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function exportCertificatesUnit() {\n  const metaConfig = await fs.readJsonSync('meta.json');\n  const { cluster, name } = metaConfig;\n\n  const NAMESPACE = process.env.NAMESPACE;\n\n  const { namespace, app, tls } = cluster;\n  if (await verifyClusterDirectory()) {\n    cd(currentPath);\n    $.verbose = true;\n\n    if (tls) {\n      const certificatJsonRaw =\n        await $`kubectl get secret certificat-${app}-${name} -n ${NAMESPACE} -o json`;\n\n      await vaultKvCertsToVault(certificatJsonRaw.stdout);\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n//  EXPORT CERTIFICATS ENTRY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function exportCerts(options) {\n  const { all } = options;\n\n  await connectToCluster();\n\n  if (all) {\n    await exportCertificatesAll();\n  } else {\n    await exportCertificatesUnit();\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// IMPORT CERTIFICATS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function importCerts() {\n  if (await verifyClusterDirectory()) {\n    cd(currentPath);\n    $.verbose = true;\n\n    const metaConfig = await fs.readJsonSync('meta.json');\n\n    let { name, cluster } = metaConfig;\n\n    const { tls, namespace, app } = cluster;\n\n    await $`kubectl config set-context --current --namespace=${process.env.NAMESPACE}`;\n\n    const certificateName = `certificat-${app}-${name}`;\n\n    const certsRaw = await vaultKvCertsToLocal();\n\n    if (tls === true && certsRaw !== '') {\n      const certsRaw = await vaultKvCertsToLocal();\n      const certsUnfiltered = JSON.parse(certsRaw);\n      // remove a property metadata.creationTimestamp\n      const certs = _.omit(certsUnfiltered, [\n        'metadata.creationTimestamp',\n        'metadata.resourceVersion',\n        'metadata.uid',\n      ]);\n      const randomFilename = Math.floor(Math.random() * 1000000);\n      await fs.writeJSONSync(`/tmp/certificat.${randomFilename}.json`, certs);\n      $.verbose = true;\n      try {\n        await $`kubectl get secret ${certificateName}`;\n        await $`kubectl delete secret ${certificateName}`;\n      } catch (error) {\n        if (!error.stderr.includes('not found')) {\n          return;\n        }\n      }\n      await $`kubectl apply -f /tmp/certificat.${randomFilename}.json`;\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CREATE SECRETS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function createSecrets() {\n  $.verbose = true;\n  const metaConfig = await fs.readJsonSync('meta.json');\n  const { type, name, cluster } = metaConfig;\n\n  const { app, namespace } = cluster;\n\n  await $`kubectl config set-context --current --namespace=${process.env.NAMESPACE}`;\n\n  const secretName = `secrets-${app}-${name}`;\n\n  if (type === 'cluster' || type === 'pod') {\n    if (type === 'pod') {\n      config({ path: `../../.env` });\n    }\n    $.verbose = true;\n    try {\n      await $`kubectl get secret ${secretName}`;\n      await $`kubectl delete secret ${secretName}`;\n    } catch (error) {\n      if (!error.stderr.includes('not found')) {\n        return;\n      }\n    }\n\n    // verify if .env file exists\n    if (fs.existsSync('.env')) {\n      await $`kubectl create secret generic ${secretName} --from-env-file=.env`;\n    }\n  } else {\n    console.log('Not a cluster app');\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DEPlOY CLUSTER\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function deployGroupGkeToCluster(appName, options) {\n  const { tls } = options;\n\n  let appDirectoryPath = `${SRC}/app`;\n\n  let getDirectoryPath;\n\n  let appDirectories = await getDirectories(appDirectoryPath);\n\n  for (let appDirectory of appDirectories) {\n    let appMeta = await fs.readJson(\n      `${appDirectoryPath}/${appDirectory}/meta.json`\n    );\n    let { type, name } = appMeta;\n\n    if (type === 'cluster' && name === appName) {\n      getDirectoryPath = `${appDirectoryPath}/${appDirectory}`;\n    }\n  }\n\n  if (getDirectoryPath === undefined) {\n    console.log('App not found');\n    return;\n  }\n\n  cd(getDirectoryPath);\n  // loop through all directory in app\n\n  $.verbose = true;\n\n  const directories = await getDirectories(`${getDirectoryPath}/app`);\n\n  console.log(directories);\n\n  let appList = [];\n  for (const directory of directories) {\n    // read all meta.json files\n\n    let podDirectory = `${getDirectoryPath}/app/${directory}`;\n\n    const { cluster, name, type } = await fs.readJsonSync(\n      `${podDirectory}/meta.json`\n    );\n\n    const currentBranchRaw = await $`git branch --show-current`;\n    // trim the trailing newline\n    const currentBranch = currentBranchRaw.stdout.trim();\n\n    const { ignoreEnv } = cluster;\n\n    if (type === 'pod') {\n      const { priority, ignoreEnv } = cluster;\n\n      if (ignoreEnv !== undefined) {\n        // check if current branch is in ignoreEnv\n        if (ignoreEnv.includes(currentBranch)) {\n          console.log(`Ignoring ${name} on branch ${currentBranch}`);\n          continue;\n        }\n      }\n\n      appList.push({ podDirectory, priority });\n    }\n  }\n\n  const appsByPriorityGroup = _.groupBy(appList, (app) => app.priority);\n  for (let group in appsByPriorityGroup) {\n    let groupApps = appsByPriorityGroup[group];\n    for (let app in groupApps) {\n      let { podDirectory: podToDeploy } = groupApps[app];\n      console.log(128912981298);\n      cd(podToDeploy);\n      await $`run custom init`;\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// NAMESPACE SET\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function setNamespace(namespace) {\n  $.verbose = true;\n  await $`kubectl create namespace ${namespace} --dry-run=client -o yaml | kubectl apply -f -`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n//  KUBECTL APPLY FOR THE POD\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function applyPod() {\n  $.verbose = true;\n  const ENV = process.env.ENV;\n  const metaConfig = await fs.readJsonSync('meta.json');\n  const { cluster } = metaConfig;\n\n  let environment;\n\n  if (ENV === 'prod' || ENV === 'preview') {\n    environment = ENV;\n  } else {\n    environment = 'dev';\n  }\n\n  await $`kubectl config set-context --current --namespace=${process.env.NAMESPACE}`;\n\n  await $`kustomize build --load-restrictor LoadRestrictionsNone ${currentPath}/k8s/${environment} | kubectl apply -f -`;\n\n  // await $`kustomize build --load-restrictor LoadRestrictionsNone ${currentPath}/k8s/${environment} > ${SRC}/kusomize.yaml`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function cluster(program) {\n  const cluster = program.command('cluster');\n  cluster.description('manage cluster');\n\n  const certs = cluster.command('certs');\n  const secrets = cluster.command('secrets');\n  const deploy = cluster.command('deploy');\n  const remove = cluster.command('remove');\n  const connect = cluster.command('connect');\n  const pod = cluster.command('pod');\n  const namespace = cluster.command('namespace');\n\n  connect\n    .description('connect to cluster')\n    .argument('[clusterName]', 'cluster name')\n    .action(connectToCluster);\n\n  secrets\n    .command('create')\n    .description('from local .env to gke secret')\n    .action(createSecrets);\n\n  certs\n    .command('export')\n    .description('from gke secrets to vault secrets')\n    .option('--all', 'export all cluster apps tls certificates')\n    .action(exportCerts);\n  certs\n    .command('import')\n    .description('from vault secrets to gke credential secrets')\n    .action(importCerts);\n\n  deploy\n    .argument('[name]', 'app name')\n    .option('--no-tls', 'do not get certificates from vault')\n    .action(deployGroupGkeToCluster);\n\n  namespace.command('set').argument('[name]', 'namespace').action(setNamespace);\n\n  pod.command('apply').action(applyPod);\n}\n",
  "src/lib/command-custom.mjs": "import * as zx from 'zx';\nimport { createRequire } from 'module';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n  setSecretsUptoProject,\n} from '../utils/divers.mjs';\n\n////////////////////////////////////////////////////////////////////////////////\n//  SETTING UP ZX\n////////////////////////////////////////////////////////////////////////////////\n\nconst { $, cd, sleep, fs } = zx;\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// EXPOSE NPM MODULE\n////////////////////////////////////////////////////////////////////////////////\n\nconst require = createRequire(import.meta.url);\nconst pathZx = require.resolve('zx');\n\nprocess.env.ZX = pathZx;\n\n////////////////////////////////////////////////////////////////////////////////\n// CUSTOM CONFIG DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\nconst customConfigDefault = {\n  root: 'scripts',\n  getSecretsUpToProject: true,\n};\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN CUSTOM SCRIPT\n////////////////////////////////////////////////////////////////////////////////\n\nasync function runCustomScript(script, argument, options) {\n  let { custom_script } = await fs.readJsonSync('meta.json');\n\n  let currentPath = process.cwd();\n\n  let { test, input, dev } = options;\n\n  ////////////////////////////////////////////////////////////////////////////////\n  // CURRENT METADATA\n  ////////////////////////////////////////////////////////////////////////////////\n\n  let metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n  let testMode = test === undefined ? {} : { root: 'test' };\n\n  const SRC = process.env.SRC;\n\n  const run =\n    dev === true\n      ? `${SRC}/dev/src/bin/cmd.mjs`\n      : `${SRC}/node_modules/@ghostmind-dev/run/src/bin/cmd.mjs`;\n\n  const utils =\n    dev === true\n      ? `${SRC}/dev/src/main.mjs`\n      : `${SRC}/node_modules/@ghostmind-dev/run/src/main.mjs`;\n\n  const { root, getSecretsUpToProject } = {\n    ...customConfigDefault,\n    ...custom_script,\n    ...testMode,\n  };\n  cd(`${currentPath}/${root}`);\n\n  if (getSecretsUpToProject === true) {\n    await setSecretsUptoProject(currentPath);\n  }\n\n  // if there is no custom script\n  // return the list of available custom scripts\n  if (script === undefined) {\n    try {\n      const { stdout: scripts } = await $`ls *.mjs`;\n      // remove \\n from apps\n      let scriptsArray = scripts.split('\\n');\n      // removing empty element from scriptsArray\n      scriptsArray.pop();\n      console.log('Available scripts:');\n      for (let scriptAvailable of scriptsArray) {\n        scriptAvailable = scriptAvailable.replace('.mjs', '');\n        console.log(`- ${scriptAvailable}`);\n      }\n    } catch (error) {\n      console.log('no custom script found');\n    }\n    return;\n  }\n  // if there is a custom script\n  // try to run the custom script\n  try {\n    const custom_function = await import(\n      `${currentPath}/${root}/${script}.mjs`\n    );\n\n    $.verbose = true;\n\n    await custom_function.default(argument, {\n      input: input === undefined ? [] : input,\n      metaConfig,\n      currentPath,\n      zx,\n      run,\n      utils,\n      env: process.env,\n    });\n  } catch (e) {\n    console.log(e);\n    console.log('something went wrong');\n  }\n}\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function commandCustom(program) {\n  const custom = program.command('custom');\n  custom\n    .description('run custom script')\n    .argument('[script]', 'script to perform')\n    .argument('[argument]', 'single argument for the script')\n    .option('-i, --input <items...>', 'multiple arguments for the script')\n    .option('--dev', 'run in dev mode')\n    .option('--test', 'run in test mode')\n    .action(runCustomScript);\n}\n",
  "src/lib/command-db.mjs": "import { $, which, sleep, cd, fs } from 'zx';\nimport core from '@actions/core';\nimport { Storage } from '@google-cloud/storage';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from '../utils/divers.mjs';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\n////////////////////////////////////////////////////////////////////////////////\n// postgresql\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function exportPostgresql(options) {\n  let ENV = process.env.ENV;\n\n  $.verbose = true;\n\n  const PGDATABASE = process.env.PGDATABASE;\n  const RUN_RUN_SERVICE_ACCOUNT_PATH = process.env.RUN_RUN_SERVICE_ACCOUNT_PATH;\n  const GCP_PROJECT_NAME = process.env.GCP_PROJECT_NAME;\n\n  const storage = new Storage({ keyFilename: RUN_RUN_SERVICE_ACCOUNT_PATH });\n\n  const modifiers = {\n    prefix: `db/${ENV}/${PGDATABASE}`,\n  };\n\n  const [files] = await storage\n    .bucket(`bucket-${GCP_PROJECT_NAME}`)\n    .getFiles(modifiers);\n\n  // verify if array has an element with the same name\n\n  const fileExists = files.some((file) =>\n    file.metadata.name.includes('db.sql')\n  );\n\n  const { local } = options;\n\n  await $`pg_dump ${PGDATABASE} > /tmp/db.sql`;\n\n  if (local) return true;\n\n  $.verbose = false;\n\n  const CURRENT_TIME_IN_MS = await $`date +%s%N | cut -b1-13`;\n\n  // remove /n from the end of the string\n  const CURRENT_TIME_IN_MS_STR = CURRENT_TIME_IN_MS.stdout.replace(\n    /(\\r)/gm,\n    ''\n  );\n\n  $.verbose = true;\n\n  const dbAddress = `gs://bucket-${GCP_PROJECT_NAME}/db/${ENV}/${PGDATABASE}/db.sql`;\n  const dbAddressBackup = `gs://bucket-${GCP_PROJECT_NAME}/db/${ENV}/${PGDATABASE}/backup/db.${CURRENT_TIME_IN_MS_STR}.sql`;\n\n  // verify if dbAddress exists\n\n  if (fileExists) {\n    await $`gsutil cp -r ${dbAddress} ${dbAddressBackup}`;\n  }\n\n  await $`gsutil cp -J /tmp/db.sql gs://bucket-${GCP_PROJECT_NAME}/db/${ENV}/${PGDATABASE}/`;\n\n  await $`rm /tmp/db.sql`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function db(program) {\n  const db = program.command('db');\n  db.description('database management');\n\n  const dbPostgresql = db\n    .command('postgres')\n    .description('manage postgresql db');\n\n  const dbHasura = db\n    .command('hasura')\n    .description('manage hasura metadata and migrations');\n\n  dbHasura\n    .command('console')\n    .description('open hasura console')\n    .action(`run hasura console`);\n\n  const dbPostgresqlExport = dbPostgresql\n    .command('backup')\n    .option('--local', 'export to local')\n    .description('export postgresql db')\n    .action(exportPostgresql);\n}\n",
  "src/lib/command-docker.mjs": "import { $, which, sleep, cd, fs } from \"zx\";\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n  withMetaMatching,\n  recursiveDirectoriesDiscovery,\n} from \"../utils/divers.mjs\";\nimport _ from \"lodash\";\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// GET DOCKERFILE NAME AND IMAGE NAME\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function getDockerfileAndImageName() {\n  const ENV = `${process.env.ENV}`;\n  let currentPath = await detectScriptsDirectory(process.cwd());\n  let metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n  let { type, scope, docker } = await verifyIfMetaJsonExists(currentPath);\n  let { root } = docker;\n\n  let dockerFileName;\n  let dockerfile;\n  let dockerContext;\n\n  if (type === \"container\") {\n    let { context_dockerfile } = docker;\n\n    if (scope === \"global\") {\n      dockerFileName = `Dockerfile`;\n    } else if (context_dockerfile === false) {\n      dockerFileName = `Dockerfile`;\n    } else if (ENV === \"prod\" || ENV === \"preview\") {\n      dockerFileName = `Dockerfile.prod`;\n    } else {\n      dockerFileName = `Dockerfile.dev`;\n    }\n\n    dockerfile = `${currentPath}/${dockerFileName}`;\n    dockerContext = `${currentPath}`;\n  } else if (root !== undefined) {\n    dockerContext = `${currentPath}/${root}`;\n\n    metaConfig = await verifyIfMetaJsonExists(dockerContext);\n\n    let { context_dockerfile } = metaConfig.docker;\n\n    if (scope === \"global\") {\n      dockerFileName = `Dockerfile`;\n    } else if (context_dockerfile === false) {\n      dockerFileName = `Dockerfile`;\n    } else if (ENV === \"prod\" || ENV === \"preview\") {\n      dockerFileName = `Dockerfile.prod`;\n    } else {\n      dockerFileName = `Dockerfile.dev`;\n    }\n    dockerfile = `${currentPath}/${root}/${dockerFileName}`;\n    cd(dockerContext);\n  }\n\n  $.verbose = true;\n  let { image, tag } = metaConfig.docker;\n  if (scope === \"global\") {\n    image = `${image}:${tag || \"latest\"}`;\n  } else {\n    image = `${image}:${tag || ENV}`;\n  }\n\n  return { dockerfile, dockerContext, image };\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// GET LATEST IMAGE DIGEST\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function getDockerImageDigest() {\n  let { image } = await getDockerfileAndImageName();\n\n  const imageDigestRaw =\n    await $`docker inspect --format='{{index .RepoDigests 0}}' ${image}`;\n\n  //  remove /n from the end of the string\n  const imageDigest = imageDigestRaw.stdout.slice(0, -1);\n  return imageDigest;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER PUSH ENTRYPOINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerPushActionEntry(options) {\n  const { all } = options;\n\n  if (all) {\n    await dockerPushAll();\n  } else {\n    await dockerPushUnit();\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER PUSH ALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerPushAll() {\n  let metaConfig = await fs.readJsonSync(\"meta.json\");\n\n  let { docker } = metaConfig;\n\n  if (docker !== undefined) {\n    if (docker.root !== undefined) {\n      let allDirectories = await recursiveDirectoriesDiscovery(\n        `${currentPath}/${docker.root}`\n      );\n\n      // remove first element of the array\n\n      for (let directory of allDirectories) {\n        let metaConfig = await verifyIfMetaJsonExists(directory);\n\n        if (metaConfig && metaConfig.type === \"container\") {\n          $.verbose = true;\n\n          cd(directory);\n\n          await dockerPushUnit();\n        }\n      }\n    }\n  } else {\n    console.log(\"No docker configuration found\");\n  }\n\n  cd(currentPath);\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER PUSH UNIT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerPushUnit() {\n  const { image } = await getDockerfileAndImageName();\n\n  await $`docker push ${image}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER BUILDX\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerBuildxActionEntry(options) {\n  const { all, mutli } = options;\n\n  if (all) {\n    await dockerBuildxAll(options);\n  } else {\n    await dockerBuildxUnit(options);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER BUILD UNIT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerBuildxUnit(options) {\n  const { amd64, multi } = options;\n\n  const { dockerfile, dockerContext, image } =\n    await getDockerfileAndImageName();\n\n  // Determine the machine architecture\n  const ARCHITECTURE = process.arch;\n\n  if (multi) {\n    // Ensure a buildx builder instance exists and is bootstrapped\n    try {\n      await $`docker buildx use mybuilder`;\n    } catch {\n      // If 'mybuilder' doesn't exist, create and bootstrap it\n      await $`docker buildx create --name mybuilder --use`;\n      await $`docker buildx inspect mybuilder --bootstrap`;\n    }\n\n    const instructions = `docker buildx build --platform linux/amd64,linux/arm64 -t ${image} --file ${dockerfile} --push ${dockerContext}`;\n\n    // transfor the instructions into an array\n\n    const instructionsArray = instructions.split(\" \");\n    await $`docker buildx create --use`;\n    await $`${instructionsArray}`;\n  } else {\n    console.log(\"Should move from docker build to docker buildx\");\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER BUILD ALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerBuildxAll(options) {\n  let metaConfig = await fs.readJsonSync(\"meta.json\");\n  let { docker } = metaConfig;\n  if (docker !== undefined) {\n    if (docker.root !== undefined) {\n      let allDirectories = await recursiveDirectoriesDiscovery(\n        `${currentPath}/${docker.root}`\n      );\n      // remove first element of the array\n      for (let directory of allDirectories) {\n        let metaConfig = await verifyIfMetaJsonExists(directory);\n        if (metaConfig && metaConfig.type === \"container\") {\n          $.verbose = true;\n          cd(directory);\n          await dockerBuildxUnit(options);\n        }\n      }\n    }\n  } else {\n    console.log(\"No docker configuration found\");\n  }\n  cd(currentPath);\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER BUILD\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerBuildActionEntry(options) {\n  const { all, amd64 } = options;\n\n  if (all) {\n    await dockerBuildAll(options);\n  } else {\n    await dockerBuildUnit(options);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER BUILD ALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function dockerBuildAll(options) {\n  let metaConfig = await fs.readJsonSync(\"meta.json\");\n  let { docker } = metaConfig;\n  if (docker !== undefined) {\n    if (docker.root !== undefined) {\n      let allDirectories = await recursiveDirectoriesDiscovery(\n        `${currentPath}/${docker.root}`\n      );\n      // remove first element of the array\n      for (let directory of allDirectories) {\n        let metaConfig = await verifyIfMetaJsonExists(directory);\n        if (metaConfig && metaConfig.type === \"container\") {\n          $.verbose = true;\n          cd(directory);\n          await dockerBuildUnit(options);\n        }\n      }\n    }\n  } else {\n    console.log(\"No docker configuration found\");\n  }\n  cd(currentPath);\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DOCKER BUILD UNIT\n////////////////////////////////////////////////////////////////////////////////\nexport async function dockerBuildUnit(options) {\n  const { amd64 } = options;\n\n  const { dockerfile, dockerContext, image } =\n    await getDockerfileAndImageName();\n\n  // Determine the machine architecture\n  const ARCHITECTURE = process.arch;\n\n  if (amd64) {\n    // Ensure a buildx builder instance exists and is bootstrapped\n    try {\n      await $`docker buildx use mybuilder`;\n    } catch {\n      // If 'mybuilder' doesn't exist, create and bootstrap it\n      await $`docker buildx create --name mybuilder --use`;\n      await $`docker buildx inspect mybuilder --bootstrap`;\n    }\n\n    // Use buildx for building amd64 image or if the host machine is ARM64\n    await $`docker buildx build --load --platform linux/amd64 -t ${image} -f ${dockerfile} ${dockerContext}`;\n  } else {\n    await $`docker build -t ${image} -f ${dockerfile} ${dockerContext}`;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function commandDocker(program) {\n  const docker = program.command(\"docker\");\n  docker.description(\"docker commands\");\n\n  const dockerBuild = docker.command(\"build\");\n  dockerBuild.description(\"Build docker image\");\n  dockerBuild.option(\"-a, --all\", \"Build all docker images\");\n  dockerBuild.option(\"--amd64\", \"Build amd64 docker image\");\n  dockerBuild.option(\"--arm64\", \"Build arm64 docker image\");\n  dockerBuild.action(dockerBuildActionEntry);\n\n  const dockerBuildx = docker.command(\"buildx\");\n  dockerBuildx.description(\"Build multiplaform docker image\");\n  dockerBuildx.option(\"-a, --all\", \"Build all docker images\");\n  dockerBuildx.option(\"--multi\", \"Build multiplaform docker image\");\n  dockerBuildx.action(dockerBuildxActionEntry);\n\n  const dockerPush = docker.command(\"push\");\n  dockerPush.description(\"Push docker image\");\n  dockerPush.option(\"-a, --all\", \"Push all docker images\");\n  dockerPush.action(dockerPushActionEntry);\n}\n",
  "src/lib/command-ghost.mjs": "import { $, cd } from \"zx\";\nimport {\n  verifyIfMetaJsonExists,\n  detectScriptsDirectory,\n} from \"../utils/divers.mjs\";\nimport { initializeAgentExecutorWithOptions } from \"langchain/agents\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { z } from \"zod\";\nimport { StructuredTool } from \"langchain/tools\";\nimport readline from \"readline\";\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// TOOL: GET TREE OF DIRECTORIES\n////////////////////////////////////////////////////////////////////////////////\n\nclass GetTreeViewFromCurrentDirectory extends StructuredTool {\n  schema = z.object({});\n  name = \"GetTreeViewFromCurrentDirectory\";\n\n  description = \"Get tree of directories from current directory\";\n\n  constructor() {\n    super(...arguments);\n  }\n\n  async _call() {\n    // call tree and ignore node_modules\n    const directories = await $`tree -I node_modules`;\n\n    return `${directories}`;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TOOL: EXECUTE A COMMAND\n////////////////////////////////////////////////////////////////////////////////\n\nclass ExecuteCommand extends StructuredTool {\n  schema = z.object({\n    commands: z.array(z.string()),\n    return_last_command: z.boolean().optional(),\n  });\n\n  name = \"ExecuteCommand\";\n\n  description = \"Execute a command.Only one command at the time\";\n\n  constructor() {\n    super(...arguments);\n  }\n\n  async _call({ commands, result }) {\n    // teansform command to array\n\n    $.verbose = true;\n\n    await $`pwd`;\n\n    // execute all commands. for the last command, return the result\n\n    let numberOfCommands = commands.length;\n\n    for (let i = 0; i < numberOfCommands; i++) {\n      const commandRaw = commands[i];\n\n      const command = commandRaw.split(\" \");\n\n      let resultRaw = await $`${command}`;\n\n      if (i === numberOfCommands - 1) {\n        if (result) {\n          return resultRaw;\n        }\n      }\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function ghost(program) {\n  const ghost = program.command(\"ghost\");\n  ghost.description(\"I will try my best to help\");\n  ghost.action(async () => {\n    $.verbose = true;\n\n    const greating = \"How can I help you? \";\n\n    // get input from user\n\n    const rl = readline.createInterface({\n      input: process.stdin,\n      output: process.stdout,\n    });\n\n    rl.question(greating, async (userRequest) => {\n      const chat = new ChatOpenAI({ modelName: \"gpt-4\", temperature: 0 });\n\n      const tools = [\n        new GetTreeViewFromCurrentDirectory(),\n        new ExecuteCommand(),\n      ];\n\n      const executor = await initializeAgentExecutorWithOptions(tools, chat, {\n        agentType: \"openai-functions\",\n        verbose: true,\n      });\n\n      const result = await executor.run(`\n\n        You will be answer command line questions.\n\n        When you receive a question, you need to undestand your environment.\n\n        if you need to perform a command that requires a specific directory, you need to get a view of the directories.\n\n        WHen ask about opening a project, always execute the command in the folder, not on a file.\n\n        Quesiton: ${userRequest}\n\n        `);\n      console.log(result);\n      rl.close();\n    });\n  });\n}\n",
  "src/lib/command-github.mjs": "import { $, which, sleep, cd, fs } from 'zx';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from '../utils/divers.mjs';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\nconst GCP_PROJECT_NAME = process.env.GCP_PROJECT_NAME;\nconst GCP_SERVICE_ACCOUNT_ADMIN = process.env.GCP_SERVICE_ACCOUNT_ADMIN;\nconst VAULT_ROOT_TOKEN = process.env.VAULT_ROOT_TOKEN;\nconst VAULT_ADDR = process.env.VAULT_ADDR;\nconst GCP_PROJECT_ID = process.env.GCP_PROJECT_ID;\nconst GH_TOKEN = process.env.GITHUB_TOKEN;\n\n////////////////////////////////////////////////////////////////////////////////\n// ACTION DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nconst actionConfigDefault = {};\n\n////////////////////////////////////////////////////////////////////////////////\n// ACT DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////'\n\nconst coreSecrets = {\n  GCP_PROJECT_ID,\n  GCP_PROJECT_NAME,\n  GCP_SERVICE_ACCOUNT_ADMIN,\n  VAULT_ROOT_TOKEN,\n  VAULT_ADDR,\n  GH_TOKEN,\n};\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// VERIFY IF IT IS A PROJECT DIRECTORY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function verifyProjectDirectory() {\n  const metaConfig = await fs.readJsonSync(`meta.json`);\n\n  const { type } = metaConfig;\n  if (type !== 'project') {\n    console.log('type is not project');\n    return false;\n  }\n  return true;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CREATE GITHUB SECRETS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function setGithubSecrets() {\n  if (await verifyProjectDirectory()) {\n    for (let secret in coreSecrets) {\n      await fs.appendFileSync(\n        '/tmp/.env',\n        `${secret}=${coreSecrets[secret]}\\n`\n      );\n    }\n    await $`gh secret set --env-file /tmp/.env`;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CREATE GITHUB SECRETS\n////////////////////////////////////////////////////////////////////////////////\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function github(program) {\n  const github = program.command('github');\n  github.description('set github environment');\n\n  const githubSecrets = github.command('secrets');\n\n  githubSecrets.description('manage github secrets');\n  const githubSecretsImport = githubSecrets.command('import');\n  githubSecretsImport\n    .description('set githubu secrets')\n    .action(setGithubSecrets);\n}\n",
  "src/lib/command-hasura.mjs": "import { $, which, sleep, cd, fs } from 'zx';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from '../utils/divers.mjs';\n\n//////////////////////////////////////////////////////////////////////////////\n// CLEANING MIGRATIONS\n//////////////////////////////////////////////////////////////////////////////\n\n// https://hasura.io/docs/latest/migrations-metadata-seeds/resetting-migrations-metadata\n// live hasura cmd migrate delete --all --database-name default\n// live hasura migrate create init\n// live hasura cmd metadata export\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// ACTION DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nconst hasuraConfigDefault = {\n  state: 'container/state',\n};\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN ACTION LOCALLY WITH ACT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function hasuraOpenConsole() {\n  const metaConfig = await fs.readJsonSync('meta.json');\n\n  const { hasura: hasuraConfig } = metaConfig;\n\n  const { state } = { ...hasuraConfigDefault, ...hasuraConfig };\n\n  cd(`${currentPath}/${state}`);\n\n  $.verbose = true;\n  await $`hasura console --no-browser --skip-update-check`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// SQUASH MIGRATIONS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function hasuraMigrateSquash(version) {\n  const metaConfig = await fs.readJsonSync('meta.json');\n\n  const { hasura: hasuraConfig } = metaConfig;\n\n  const { state } = { ...hasuraConfigDefault, ...hasuraConfig };\n\n  cd(`${currentPath}/${state}`);\n\n  $.verbose = true;\n  await $`hasura migrate squash --from ${version} --database-name default`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CREATE MIGRATIONS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function hasuraMigrateCreate(name) {\n  const metaConfig = await fs.readJsonSync('meta.json');\n\n  const { hasura: hasuraConfig } = metaConfig;\n\n  const { state } = { ...hasuraConfigDefault, ...hasuraConfig };\n\n  cd(`${currentPath}/${state}`);\n\n  $.verbose = true;\n\n  await $`hasura migrate create \"${name}\" --from-server --database-name default`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// APPLY MIGRATIONS\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function hasuraMigrateApply(version) {\n  const metaConfig = await fs.readJsonSync('meta.json');\n\n  const { hasura: hasuraConfig } = metaConfig;\n\n  const { state } = { ...hasuraConfigDefault, ...hasuraConfig };\n\n  cd(`${currentPath}/${state}`);\n\n  $.verbose = true;\n  await $`hasura migrate apply --version ${version} --skip-execution --database-name default`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n//  HASURA GLOBAL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function hasuraGlobalCmd(commands, options) {\n  const metaConfig = await fs.readJsonSync('meta.json');\n\n  const { hasura: hasuraConfig } = metaConfig;\n\n  const { databaseName, all } = options;\n\n  const { state } = { ...hasuraConfigDefault, ...hasuraConfig };\n\n  cd(`${currentPath}/${state}`);\n\n  $.verbose = true;\n\n  if (databaseName !== undefined) {\n    commands.push(`--database-name`);\n    commands.push(`${databaseName}`);\n  }\n\n  if (all) {\n    commands.push(`--all`);\n  }\n\n  await $`hasura ${commands}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n//  EXPORT SCHEMA\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function hasuraSchemaExportToLocal() {\n  const HASURA_GRAPHQL_API_ENDPOINT = process.env.HASURA_GRAPHQL_API_ENDPOINT;\n  const HASURA_GRAPHQL_ADMIN_SECRET = process.env.HASURA_GRAPHQL_ADMIN_SECRET;\n  const SRC = process.env.SRC;\n\n  await $`gq ${HASURA_GRAPHQL_API_ENDPOINT} -H \"X-Hasura-Admin-Secret: ${HASURA_GRAPHQL_ADMIN_SECRET}\" --introspect > ${SRC}/schema.graphql`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function hasura(program) {\n  const hasura = program.command('hasura');\n  hasura.description('perform hasura maintenances');\n\n  const hasuraCommand = hasura.command('cmd');\n  hasuraCommand\n    .argument('[commands...]', 'command to run')\n    .option('--database-name <database-name>', 'database name')\n    .option('--all', 'all migrations')\n    .action(hasuraGlobalCmd);\n\n  const hasuraConsole = hasura.command('console');\n  const hasuraMigrate = hasura.command('migrate');\n  const hasuraMetadata = hasura.command('metadata');\n\n  hasuraConsole\n    .description('open hasura console locally ')\n    .action(hasuraOpenConsole);\n\n  const migrateSquash = hasuraMigrate.command('squash');\n  migrateSquash\n    .description('squash all migrations')\n    .argument('<version>', 'version to squash to')\n    .action(hasuraMigrateSquash);\n\n  const migrateApply = hasuraMigrate.command('apply');\n  migrateApply\n    .description('apply all migrations')\n    .argument('<version>', 'version to apply')\n    .action(hasuraMigrateApply);\n\n  const migrateCreate = hasuraMigrate.command('create');\n  migrateCreate\n    .description('create a new migration from current schema')\n    .argument('<name>', 'name of the migration')\n    .action(hasuraMigrateCreate);\n\n  const hasuraSchema = hasura.command('schema');\n\n  // const hasuraSchemaExport = hasuraSchema.command('export');\n  // hasuraSchemaExport\n  //   .description('exporSchemat schema')\n  //   .action(hasuraExportToLocal);\n\n  const hasuraMetadataApply = hasuraMetadata.command('apply');\n  hasuraMetadataApply.description('apply metadata').action(async () => {\n    const metaConfig = await fs.readJsonSync('meta.json');\n\n    const { hasura: hasuraConfig } = metaConfig;\n\n    const { state } = { ...hasuraConfigDefault, ...hasuraConfig };\n\n    cd(`${currentPath}/${state}`);\n\n    $.verbose = true;\n    await $`hasura metadata apply --skip-update-check`;\n  });\n}\n",
  "src/lib/command-lib.mjs": "import { $, which, sleep, cd } from 'zx';\nimport core from '@actions/core';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from '../utils/divers.mjs';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\nconst LOCALHOST_SRC =\n  process.env.CODESPACES === 'true'\n    ? process.env.SRC\n    : process.env.LOCALHOST_SRC;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING LIB\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function runLib(cmd) {\n  // convert .arugment --argumaent\n\n  $.verbose = true;\n\n  const clean = cmd.map((arg) => {\n    if (arg.startsWith('.')) {\n      return arg.replace('.', '--');\n    }\n    return arg;\n  });\n\n  await $`${clean}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\nexport default async function lib(program) {\n  const lib = program.command('lib');\n  lib.argument('<cmd> [env...]', 'command to run');\n  lib.description('run utils with context');\n  lib.action(runLib);\n}\n",
  "src/lib/command-machine.mjs": "import { $, which, sleep, cd, fs } from \"zx\";\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from \"../utils/divers.mjs\";\nimport inquirer from \"inquirer\";\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// INIT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function machineInit() {\n  // ask for the project name\n\n  const { projectName } = await inquirer.prompt([\n    {\n      type: \"input\",\n      name: \"projectName\",\n      message: \"What is the name of the project?\",\n    },\n  ]);\n\n  await $`git clone https://github.com/ghostmind-dev/machine.git ${projectName}`;\n\n  // remove the user path from currentPath\n\n  const pathFromHome = currentPath.replace(`${process.env.HOME}/`, \"\");\n\n  cd(projectName);\n\n  // we have to change so value in a few files. First\n  // First is the .devcontainer/devcontainer.json file\n  // Get the json file and parse it\n\n  let devcontainer = await fs.readFile(\n    `${currentPath}/${projectName}/.devcontainer/devcontainer.json`,\n    \"utf8\"\n  );\n\n  devcontainer = JSON.parse(devcontainer);\n\n  // Change the name of the container\n\n  devcontainer.name = projectName;\n  devcontainer.build.args.PROJECT_DIR =\n    \"${env:HOME}${env:USERPROFILE}/\" + pathFromHome + \"/\" + projectName;\n  devcontainer.remoteEnv.LOCALHOST_SRC =\n    \"${env:HOME}${env:USERPROFILE}/\" + pathFromHome + \"/\" + projectName;\n  devcontainer.mounts[2] = `source=ghostmind-${projectName}-history,target=/commandhistory,type=volume`;\n  devcontainer.mounts[2] = `source=ghostmind-${projectName}-history,target=/commandhistory,type=volume`;\n  devcontainer.mounts[3] =\n    \"source=${env:HOME}${env:USERPROFILE}/\" +\n    pathFromHome +\n    \"/\" +\n    projectName +\n    \",\" +\n    `target=${process.env.HOME}/${pathFromHome}/${projectName},type=bind`;\n\n  devcontainer.runArgs[2] = `devcontainer-${projectName}`;\n\n  // write the file back\n\n  await fs.writeFile(\n    `${currentPath}/${projectName}/.devcontainer/devcontainer.json`,\n    JSON.stringify(devcontainer, null, 2),\n    \"utf8\"\n  );\n\n  // now , we need to modify ./meta.json\n\n  let meta = await fs.readFile(\n    `${currentPath}/${projectName}/meta.json`,\n    \"utf8\"\n  );\n\n  meta = JSON.parse(meta);\n\n  meta.name = projectName;\n\n  await fs.writeFile(\n    `${currentPath}/${projectName}/meta.json`,\n    JSON.stringify(meta, null, 2),\n    \"utf8\"\n  );\n\n  // now we need replace the content of Readme.md and only write a ssingle line header\n\n  await fs.writeFile(\n    `${currentPath}/${projectName}/Readme.md`,\n    `# ${projectName}`,\n    \"utf8\"\n  );\n  $.verbose = true;\n\n  await $`run vault kv export`;\n\n  await $`run utils meta ids`;\n\n  await $`run vault kv import`;\n\n  await $`rm -rf .git`;\n\n  await $`git init`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function machine(program) {\n  const machine = program.command(\"machine\");\n  machine.description(\"create a devcontainer for the project\");\n\n  const init = machine.command(\"init\");\n  init.description(\"create a devcontainer for the project\");\n  init.action(machineInit);\n}\n",
  "src/lib/command-skaffold.mjs": "import { $, which, sleep, cd, fs } from 'zx';\nimport * as inquirer from 'inquirer';\nimport { connectToCluster } from './command-cluster.mjs';\nimport { execFileSync } from 'child_process';\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n  getDirectories,\n  recursiveDirectoriesDiscovery,\n} from '../utils/divers.mjs';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// SKAFFOLD DEV ENTRY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function skaffoldDevEntry(profile, options) {\n  const { group } = options;\n\n  if (group) {\n    await skaffoldGroup(options, 'dev');\n    return;\n  }\n  await skaffoldUnit(profile, options, 'dev');\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// SKAFFOLD DEV ENTRY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function skaffoldRunEntry(profile, options) {\n  const { group } = options;\n\n  if (group) {\n    await skaffoldGroup(options, 'run');\n    return;\n  }\n  await skaffoldUnit(profile, options, 'run');\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// SKAFFOLD UNIT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function skaffoldUnit(profile, options, action) {\n  const { statusCheck, force = false, cacheArtifacts } = options;\n  process.env.FORCE_COLOR = 1;\n  const { status, message } = await connectToCluster();\n\n  if (status === 'error') {\n    console.log(message);\n    return;\n  }\n\n  $.verbose = true;\n\n  cd(currentPath);\n\n  try {\n    const skaffoldOptions = [\n      action,\n      '--cleanup=false',\n      `--profile=${profile}`,\n      `--status-check=${statusCheck}`,\n      `--force=${force}`,\n      `--cache-artifacts=${cacheArtifacts}`,\n    ];\n\n    // keep execFileSync instead of zx\n    // to maintain script outpu color\n\n    execFileSync('skaffold', skaffoldOptions, {\n      stdio: 'inherit',\n      cwd: currentPath,\n    });\n  } catch (e) {\n    console.log(e);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN ACTION LOCALLY WITH ACT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function skaffoldGroup(options, action) {\n  const { statusCheck, force = false, cacheArtifacts } = options;\n  process.env.FORCE_COLOR = 1;\n  const { status, message } = await connectToCluster();\n\n  if (status === 'error') {\n    console.log(message);\n    return;\n  }\n\n  const app_directory = `${currentPath}`;\n  const groupe = [];\n\n  let directories = await recursiveDirectoriesDiscovery(app_directory);\n\n  for (let directory of directories) {\n    const metaConfig = await verifyIfMetaJsonExists(directory);\n\n    if (metaConfig === false) {\n      continue;\n    }\n\n    const { skaffold, name } = metaConfig;\n\n    if (skaffold == undefined) {\n      continue;\n    }\n\n    const { group } = skaffold;\n    for (let groupInMeta of group) {\n      const matchIndex = groupe.findIndex(\n        (value, index) => value.name === groupInMeta\n      );\n      if (matchIndex > -1) {\n        groupe[matchIndex] = {\n          ...groupe[matchIndex],\n          members: [...groupe[matchIndex].members, { name, directory }],\n        };\n        continue;\n      }\n      groupe.push({\n        name: groupInMeta,\n        members: [{ name, directory }],\n      });\n    }\n  }\n\n  const prompt = inquirer.createPromptModule();\n  const result = await prompt({\n    type: 'list',\n    name: 'answer',\n    message: 'Which groupe to initiate ?',\n    choices: groupe.map((value) => value.name),\n    pageSize: 20,\n  });\n  const groupInitializationIndex = groupe.findIndex(\n    (value) => value.name === result.answer\n  );\n  let profiles = '';\n  groupe[groupInitializationIndex].members.map((value) => {\n    profiles = `${profiles},${value.name}`;\n  });\n  $.verbose = true;\n  try {\n    const skaffoldOptions = [\n      action,\n      '--cleanup=false',\n      `--profile=${profiles.substring(1)}`,\n      `--status-check=${statusCheck}`,\n      `--force=${force}`,\n      `--cache-artifacts=${cacheArtifacts}`,\n    ];\n\n    execFileSync('skaffold', skaffoldOptions, {\n      stdio: 'inherit',\n      cwd: currentPath,\n    });\n  } catch (e) {\n    console.log(e);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function skaffold(program) {\n  const skaffold = program.command('skaffold');\n  skaffold.description('local cluster development');\n\n  const dev = skaffold.command('dev');\n  const run = skaffold.command('run');\n  dev\n    .description('launch cluster apps with skaffold in dev mode')\n    .argument('[profile]', 'profile to run')\n    .option('--group', 'group name to run')\n    .option('--no-status-check', 'disable status check')\n    .option('--force', 'rebuild images')\n    .option('--no-cache-artifacts', 'disable cache artifacts')\n    .action(skaffoldDevEntry);\n\n  run\n    .description('launch cluster apps with skaffold')\n    .argument('[profile]', 'profile to run')\n    .option('--group', 'group name to run')\n    .option('--no-status-check', 'disable status check')\n    .option('--force', 'rebuild images')\n    .option('--no-cache-artifacts', 'disable cache artifacts')\n    .action(skaffoldRunEntry);\n}\n",
  "src/lib/command-terraform.mjs": "import { $, which, sleep, cd, fs } from \"zx\";\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n  withMetaMatching,\n} from \"../utils/divers.mjs\";\nimport _ from \"lodash\";\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nconst terraformConfigDefault = {\n  root: \"gcp\",\n};\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\nconst GCP_PROJECT_NAME = `${process.env.GCP_PROJECT_NAME}`;\n\n////////////////////////////////////////////////////////////////////////////////\n// GET BACKEND BUCKET NAME AND DIRECTORY\n////////////////////////////////////////////////////////////////////////////////\n\nasync function getBucketConfig(id, scope) {\n  const ENV = `${process.env.ENV}`;\n  let bucketDirectory;\n\n  if (scope === \"global\") {\n    bucketDirectory = `${id}/global/terraform`;\n  } else {\n    let environment = ENV === \"prod\" ? \"prod\" : \"dev\";\n    bucketDirectory = `${id}/${environment}/terraform`;\n  }\n\n  $.verbose = true;\n\n  const bcBucket = `bucket=bucket-${process.env.RUN_CORE_PROJECT}`;\n  const bcPrefix = `prefix=${bucketDirectory}`;\n\n  return { bcBucket, bcPrefix };\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// GET TERAFORM ROOT AND DOCKER BUILD CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nasync function getTerraformConfig() {\n  let currentPath = await detectScriptsDirectory(process.cwd());\n\n  cd(currentPath);\n\n  let { terraform } = await fs.readJsonSync(\"meta.json\");\n\n  if (terraform === undefined) {\n    throw Error(\"terraform config not found\");\n  }\n\n  return { ...terraformConfigDefault, ...terraform };\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN TERRAFORM STATE MV\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformStateMv(\n  source_component,\n  target_component,\n  current_name,\n  new_name\n) {\n  try {\n    let metaConfig = await verifyIfMetaJsonExists(currentPath);\n    let { type } = metaConfig;\n\n    let pathResources;\n\n    if (type === \"component\") {\n      console.log(\n        `Need to be in a the parent of the root directory of the component you want to move`\n      );\n      return;\n    }\n\n    let { terraform } = metaConfig;\n\n    let { root } = terraform;\n\n    let targetResources = `${currentPath}/${root}/${target_component}`;\n\n    cd(`${targetResources}/`);\n\n    let targetMeta = await verifyIfMetaJsonExists(targetResources);\n\n    let { id: targetId, scope: targetScope } = targetMeta;\n\n    let { bcBucket: targetBcBucket, bcPrefix: targetBcPrefix } =\n      await getBucketConfig(targetId, targetScope);\n\n    await $`terraform init -backend-config=${targetBcBucket} -backend-config=${targetBcPrefix} --lock=false`;\n    await $`terraform state pull > terraform.tfstate`;\n\n    let pathTargetStateFile = `../${target_component}/terraform.tfstate`;\n\n    if (new_name === undefined) {\n      new_name = current_name;\n    }\n\n    let sourceResources = `${currentPath}/${root}/${source_component}`;\n\n    cd(`${sourceResources}/`);\n\n    let sourceMeta = await verifyIfMetaJsonExists(sourceResources);\n\n    let { id: sourceId, scope: sourceScope } = targetMeta;\n\n    let { bcBucket: sourceBcBucket, bcPrefix: sourceBcPrefix } =\n      await getBucketConfig(sourceId, sourceScope);\n\n    $.verbose = true;\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform state mv -state-out=${pathTargetStateFile} ${current_name} ${new_name}`;\n  } catch (error) {\n    console.error(error.message);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM STATE PULL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformStatePull(component) {\n  try {\n    let metaConfig = await verifyIfMetaJsonExists(currentPath);\n    let { type } = metaConfig;\n\n    let pathResources;\n\n    if (component !== undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}/${component}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    if (type !== \"component\" && component === undefined) {\n      console.log(`something is wrong`);\n      return;\n    }\n\n    let { id, scope } = metaConfig;\n\n    const { bcBucket, bcPrefix } = await getBucketConfig(id, scope);\n\n    $.verbose = true;\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform state pull > terraform.tfstate`;\n  } catch (error) {\n    console.error(error.message);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM STATE PUSH\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformStatePush(component) {\n  try {\n    let metaConfig = await verifyIfMetaJsonExists(currentPath);\n    let { type } = metaConfig;\n\n    let pathResources;\n\n    if (component !== undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}/${component}`;\n      cd(`${pathResources}/`);\n    }\n\n    if (type !== \"component\" && component === undefined) {\n      console.log(`something is wrong`);\n      return;\n    }\n\n    await $`terraform state push terraform.tfstate`;\n  } catch (error) {\n    console.error(error.message);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM IMPORT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformImport(\n  component,\n  local_resouces_path,\n  remote_resources_path\n) {\n  try {\n    let metaConfig = await verifyIfMetaJsonExists(currentPath);\n    let { type } = metaConfig;\n\n    let pathResources;\n\n    if (component !== undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}/${component}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    if (type !== \"component\" && component === undefined) {\n      console.log(`something is wrong`);\n      return;\n    }\n\n    let { id, scope } = metaConfig;\n\n    const { bcBucket, bcPrefix } = await getBucketConfig(id, scope);\n\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform import ${local_resouces_path} ${remote_resources_path}`;\n  } catch (error) {\n    console.error(error.message);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM DESTROY ENTRYPOINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformDestroyEntry(component, options) {\n  const { all, local } = options;\n\n  if (all) {\n    await terraformDestroAll(options);\n  } else {\n    await terraformDestroyUnit(component, options);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM DESTROY ALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformDestroAll(options) {\n  const metaConfig = await fs.readJsonSync(\"meta.json\");\n\n  let { root } = await getTerraformConfig();\n\n  const componentDirectories = await withMetaMatching({\n    property: \"type\",\n    value: \"component\",\n    path: `${currentPath}/${root}`,\n  });\n\n  const componentsByPriority = _.sortBy(componentDirectories, (composante) => {\n    return composante.config.terraform.priority;\n  });\n\n  for (let component of componentsByPriority) {\n    let { directory, config } = component;\n    let { id, scope } = config;\n\n    let { bcBucket, bcPrefix } = await getBucketConfig(id, scope);\n\n    cd(`${directory}/`);\n\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform plan -destroy`;\n    await $`terraform destroy -auto-approve`;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM DESTROY UNIT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformDestroyUnit(component, options) {\n  try {\n    let metaConfig = await verifyIfMetaJsonExists(currentPath);\n    let { type } = metaConfig;\n\n    let pathResources;\n\n    if (component !== undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}/${component}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    if (type !== \"component\" && component === undefined) {\n      console.log(`\n      # from parent directory\n      $ run terraform apply component\n\n      # from component directory\n      $ run terraform apply\n    `);\n      return;\n    }\n\n    let { id, scope } = metaConfig;\n\n    const { bcBucket, bcPrefix } = await getBucketConfig(id, scope);\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform plan -destroy`;\n    await $`terraform destroy -auto-approve`;\n  } catch (error) {\n    console.error(error.message);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM APPLY ENTRYPOINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformApplyEntry(component, options) {\n  const { all, local } = options;\n\n  if (all) {\n    await terraformApplyAll(options);\n  } else {\n    await terraformApplyUnit(component, options);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM APPLY ALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformApplyAll(options) {\n  const metaConfig = await fs.readJsonSync(\"meta.json\");\n\n  let { root } = await getTerraformConfig();\n\n  const componentDirectories = await withMetaMatching({\n    property: \"type\",\n    value: \"component\",\n    path: `${currentPath}/${root}`,\n  });\n\n  const componentsByPriority = _.sortBy(componentDirectories, (composante) => {\n    return composante.config.terraform.priority;\n  });\n\n  for (let component of componentsByPriority) {\n    let { directory, config } = component;\n    let { id, scope } = config;\n\n    let { bcBucket, bcPrefix } = await getBucketConfig(id, scope);\n\n    cd(`${directory}/`);\n\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform plan`;\n    await $`terraform apply -auto-approve`;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM APPLY UNIT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformApplyUnit(component, options) {\n  try {\n    let metaConfig = await verifyIfMetaJsonExists(currentPath);\n    let { type } = metaConfig;\n\n    let pathResources;\n\n    if (component !== undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}/${component}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    if (type === \"component\" && component === undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    if (type === \"container\" && component === undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    if (type === \"app\" && component === undefined) {\n      let { terraform } = metaConfig;\n      let { root } = terraform;\n      pathResources = `${currentPath}/${root}`;\n      cd(`${pathResources}/`);\n      metaConfig = await verifyIfMetaJsonExists(pathResources);\n    }\n\n    let { id, scope } = metaConfig;\n\n    const { bcBucket, bcPrefix } = await getBucketConfig(id, scope);\n\n    console.log(bcPrefix);\n\n    await $`terraform init -backend-config=${bcBucket} -backend-config=${bcPrefix} --lock=false`;\n    await $`terraform plan`;\n    await $`terraform apply -auto-approve`;\n    // await $`terraform 0.13upgrade`;\n  } catch (error) {\n    console.error(error.message);\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM APPLY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformOutput(component) {\n  try {\n    let { root } = await getTerraformConfig(component);\n\n    let pathResources = `${currentPath}/${root}/${component}`;\n\n    cd(`${pathResources}/`);\n\n    $.verbose = true;\n\n    await $`terraform output -json`;\n  } catch (error) {}\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM VARIABLES\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformVariables(env_file = \".env\") {\n  // Read the .env file\n  const content = fs.readFileSync(env_file, \"utf-8\");\n\n  // Extract all variable names that don't start with TF_VAR\n  const nonTfVarNames = content.match(/^(?!TF_VAR_)[A-Z_]+(?==)/gm);\n\n  // Generate the prefixed variable declarations for non-TF_VAR variables\n  const prefixedVars = nonTfVarNames\n    .map((varName) => {\n      const value = content.match(new RegExp(`^${varName}=(.*)$`, \"m\"))[1];\n      return `TF_VAR_${varName}=${value}`;\n    })\n    .join(\"\\n\");\n\n  // Write the prefixed variable declarations to the output.txt file\n  fs.writeFileSync(\"output.txt\", prefixedVars);\n\n  console.log(\"Output written to output.txt\");\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM ENV\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function terraformEnv() {\n  // Read the .env file\n  const content = fs.readFileSync(\".env\", \"utf-8\");\n\n  // Extract all variable names that start with TF_VAR\n  const variableNames = content.match(/^TF_VAR_[A-Z_]+(?==)/gm);\n\n  // Generate the env declarations\n  const envDeclarations = variableNames\n    .map((varName) => {\n      // Remove the \"TF_VAR_\" prefix for Terraform declarations\n      const tfName = varName.replace(/^TF_VAR_/, \"\");\n      return `\n        env {\n          name  = \"${tfName}\"\n          value = var.${tfName}\n        }\n  `;\n    })\n    .join(\"\\n\");\n\n  // Generate the variable declarations\n  const varDeclarations = variableNames\n    .map((varName) => {\n      const tfName = varName.replace(/^TF_VAR_/, \"\");\n      return `variable \"${tfName}\" {}`;\n    })\n    .join(\"\\n\");\n\n  // Write to the .txt file\n  const output = `${envDeclarations}\\n\\n${varDeclarations}`;\n  fs.writeFileSync(\"output.txt\", output);\n\n  console.log(\"Output written to output.txt\");\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function commandTerraform(program) {\n  const terraform = program.command(\"terraform\");\n  terraform.description(\"infrastructure definition\");\n\n  const tfApply = terraform.command(\"apply\");\n  const tfDestroy = terraform.command(\"destroy\");\n  const tfImport = terraform.command(\"import\");\n  const tfState = terraform.command(\"state\");\n  const tfOutput = terraform.command(\"output\");\n  const tfVariables = terraform.command(\"variables\");\n  const tfEnv = terraform.command(\"env\");\n\n  tfEnv.description(\"generate terraform env declaration\").action(terraformEnv);\n\n  tfVariables\n    .description(\"manage terraform variables\")\n    .action(terraformVariables)\n    .argument(\"[env]\", \"name of the env file\");\n\n  tfApply\n    .description(\"apply the infrastructure\")\n    .argument(\"[component]\", \"component to deploy\")\n    .option(\"--local\", \"use local state\")\n    .option(\"--all\", \"deploy all components\")\n    .action(terraformApplyEntry);\n\n  tfDestroy\n    .description(\"terminate the infrastructure\")\n    .argument(\"[component]\", \"component to destroy\")\n    .action(terraformDestroyEntry);\n\n  tfImport\n    .description(\"import the infrastructure\")\n    .argument(\"[component]\", \"component source\")\n    .argument(\"[local]\", \"local resource path\")\n    .argument(\"[remote]\", \"remote resource path\")\n    .action(terraformImport);\n\n  tfOutput\n    .description(\"output terraform process as json\")\n    .argument(\"[component]\", \"component to output\")\n    .action(terraformOutput);\n\n  tfState.description(\"manage the local and remorte state\");\n  const tfStatePull = tfState.command(\"pull\");\n  tfStatePull.argument(\"[component]\", \"component to pull\");\n  tfStatePull.action(terraformStatePull);\n  const tfStatePush = tfState.command(\"push\");\n  tfStatePush.argument(\"[component]\", \"component to push\");\n  tfStatePush.action(terraformStatePush);\n  const tfStateMv = tfState.command(\"mv\");\n  tfStateMv.argument(\"[source_component]\", \"component source\");\n  tfStateMv.argument(\"[target_component]\", \"component target\");\n  tfStateMv.argument(\"[current_name]\", \"current name of part to move\");\n  tfStateMv.argument(\"[new_name]\", \"new name after move\");\n  tfStateMv.action(terraformStateMv);\n}\n",
  "src/lib/command-utils.mjs": "import { $, cd, fs, sleep } from \"zx\";\nimport {\n  withMetaMatching,\n  verifyIfMetaJsonExists,\n  detectScriptsDirectory,\n  setSecretsUptoProject,\n  recursiveDirectoriesDiscovery,\n} from \"../utils/divers.mjs\";\nimport { nanoid } from \"nanoid\";\nimport jsonfile from \"jsonfile\";\nimport * as inquirer from \"inquirer\";\nimport path from \"path\";\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// QUICK COMMIT AMEND\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function quickAmend() {\n  $.verbose = true;\n\n  try {\n    await $`git rev-parse --is-inside-work-tree 2>/dev/null`;\n    await $`echo \"git amend will begin\" &&\n        git add . &&\n        git commit --amend --no-edit &&\n        git push origin main -f\n    `;\n  } catch (e) {\n    console.error(\"git amend failed\");\n    return;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// QUICK COMMIT AND PUSH\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function quickCommit() {\n  $.verbose = true;\n\n  try {\n    await $`echo \"git commit will begin\" &&\n        git add . &&\n        git commit -m \"quick commit\" &&\n        git push origin main -f\n    `;\n  } catch (e) {\n    console.error(\"git commit failed\");\n    return;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DEV INSTALL\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function devInstallDependencies() {\n  const directories = await withMetaMatching({ property: \"development.init\" });\n\n  for (const directoryDetails of directories) {\n    const { directory, config } = directoryDetails;\n\n    const { init } = config.development;\n\n    $.verbose = true;\n\n    for (let script of init) {\n      const scriptArray = script.split(\" \");\n\n      cd(directory);\n\n      await $`${scriptArray}`;\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CHANGE ENVIRONMENT\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function envDevcontainer() {\n  // const directories = await withMetaMatching({\n  //   property: 'scope',\n  //   value: 'environment',\n  // });\n\n  const HOME = process.env.HOME;\n\n  $.verbose = false;\n\n  const currentBranchRaw = await $`git branch --show-current`;\n  // trim the trailing newline\n  const currentBranch = currentBranchRaw.stdout.trim();\n\n  let environemnt;\n  if (currentBranch === \"main\") {\n    environemnt = \"prod\";\n  } else if (currentBranch === \"preview\") {\n    environemnt = \"preview\";\n  } else {\n    environemnt = \"dev\";\n  }\n\n  $.verbose = true;\n\n  // set environment name in zshenv\n\n  await $`echo \"export ENV=${environemnt}\" > ${HOME}/.zshenv`;\n\n  process.env.ENV = environemnt;\n\n  return environemnt;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CREATE A SHORT UUID\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function createShortUUID(options = { print: false }) {\n  const { print } = options;\n  const id = nanoid(12);\n\n  if (print) {\n    console.log(id);\n    return;\n  }\n\n  return id;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CREATE A METADATA FILE\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function createMetaFile() {\n  const id = await createShortUUID();\n\n  const prompt = inquirer.createPromptModule();\n\n  const { name } = await prompt({\n    type: \"input\",\n    name: \"name\",\n    message: \"What is the name of this object?\",\n  });\n  const { type } = await prompt({\n    type: \"input\",\n    name: \"type\",\n    message: \"What is the type of this object?\",\n  });\n  const { scope } = await prompt({\n    type: \"input\",\n    name: \"scope\",\n    message: \"What is the scope of this object?\",\n  });\n  const meta = {\n    name,\n    type,\n    scope,\n    id,\n  };\n\n  await jsonfile.writeFile(\"meta.json\", meta, { spaces: 2 });\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RUN DEVCONTAINER OSTCREATECOMMAND\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function initDevcontainer() {\n  $.verbose = true;\n\n  cd(currentPath);\n\n  await setSecretsUptoProject(currentPath);\n\n  await $`${process.env.SRC}/.devcontainer/library-scripts/post-create.mjs dev`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// CHANGE ALL IDS IN A META.JSON FILE\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function changeAllIds() {\n  const SRC = process.env.SRC || currentPath;\n\n  // ask the user if they want to change all ids\n\n  const prompt = inquirer.createPromptModule();\n\n  const { changeAllIds } = await prompt({\n    type: \"confirm\",\n    name: \"changeAllIds\",\n    message: \"Do you want to change all ids?\",\n  });\n\n  if (!changeAllIds) {\n    return;\n  }\n\n  const directories = await recursiveDirectoriesDiscovery(SRC);\n\n  for (const directory of directories) {\n    const metaConfig = await verifyIfMetaJsonExists(directory);\n\n    // if directory matches ${SRC}/dev/** continue to next iteration\n\n    if (directory.includes(`${SRC}/dev`)) {\n      continue;\n    }\n\n    if (metaConfig) {\n      metaConfig.id = nanoid(12);\n\n      await jsonfile.writeFile(path.join(directory, \"meta.json\"), metaConfig, {\n        spaces: 2,\n      });\n    }\n  }\n\n  let metaConfig = await verifyIfMetaJsonExists(SRC);\n\n  metaConfig.id = nanoid(12);\n\n  await jsonfile.writeFile(path.join(currentPath, \"meta.json\"), metaConfig, {\n    spaces: 2,\n  });\n}\n////////////////////////////////////////////////////////////////////////////////\n// COMMIT CHANGES\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function commitChangesReturn(commit) {}\n\n////////////////////////////////////////////////////////////////////////////////\n// INSTALL DEPENDENCIES\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function installDependencies() {\n  $.verbose = true;\n  await $`brew install vault`;\n\n  const VAULT_TOKEN = process.env.VAULT_ROOT_TOKEN;\n\n  await $`vault login ${VAULT_TOKEN}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// REPO\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function repoConvert(arg) {\n  const { repo } = metaConfig;\n\n  // we need to create a single json  file  with the content of the repo object\n  // {\n  //   \"type\": \"npm_package\",\n  //   \"names\": [\"@angular/core\", \"@angular/common\"],\n  //   \"repo\": {\n  //     \"folders\": [\"src\"],\n  //     \"files\": [\"package.json\", \"README.md\"],\n  //     \"ignore_extensions\": []\n  //   },\n  //   \"id\": \"ic9ETB7juz3g\"\n  // }\n  // Final out put should be:\n  // { \"src/main.mjs\": \"// main.mjs content\", \"src/other.mjs\": \"// other.mjs content\", etc... }\n\n  const { folders, files, ignore_extensions } = repo;\n\n  let filesContent = {};\n\n  for (const folder of folders) {\n    let folderList = await recursiveDirectoriesDiscovery(folder);\n\n    for (const folder of folderList) {\n      const filesInFolder = await fs.readdir(folder, {\n        withFileTypes: true,\n      });\n\n      for (const file of filesInFolder) {\n        if (file.isDirectory()) {\n          continue;\n        }\n\n        filesContent[`${folder}/${file.name}`] = await fs.readFile(\n          `${folder}/${file.name}`,\n          \"utf8\"\n        );\n      }\n\n      // let fileContent = await fs.readFile(file, \"utf8\");\n      // console.log(fileContent);\n    }\n  }\n\n  // create a single json file with the content of the repo object\n\n  await fs.writeFile(\n    `${currentPath}/repo.json`,\n    JSON.stringify(filesContent, null, 2),\n    \"utf8\"\n  );\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function utils(program) {\n  const utils = program.command(\"utils\");\n  utils.description(\"collection of utils\");\n  const git = utils.command(\"git\");\n  git.description(\"git utils\");\n  const dev = utils.command(\"dev\");\n  dev.description(\"devcontainer utils\");\n  const nanoid = utils.command(\"nanoid\");\n  dev.description(\"devcontainer utils\");\n  const meta = utils.command(\"meta\");\n  meta.description(\"meta utils\");\n  const commit = utils.command(\"commit\");\n  const dependencies = utils.command(\"dependencies\");\n  dependencies.description(\"dependencies install\");\n\n  const repo = utils.command(\"repo\");\n\n  repo.description(\"repo utils\");\n  repo.action(repoConvert);\n  repo.argument(\"[repo]\", \"repo to convert\");\n\n  const gitAmend = git.command(\"amend\");\n  gitAmend.description(\"amend the last commit\");\n  gitAmend.action(quickAmend);\n\n  const gitCommit = git.command(\"commit\");\n  gitCommit.description(\"quick commit\");\n  gitCommit.action(quickCommit);\n\n  const devInstall = dev.command(\"install\");\n  devInstall.description(\"install app dependencies\");\n  devInstall.action(devInstallDependencies);\n\n  const devInit = dev.command(\"init\");\n  devInit.description(\"devcontainer post create command\");\n  devInit.action(initDevcontainer);\n\n  const devEnv = dev.command(\"env\");\n  devEnv.description(\"change environement\");\n  devEnv.action(envDevcontainer);\n\n  const id = nanoid.command(\"id\");\n  id.description(\"generate a nanoid\");\n  id.option(\"p, --print\", \"print the id\");\n  id.action(createShortUUID);\n\n  const metaCreate = meta.command(\"create\");\n  metaCreate.description(\"create a meta.json file\");\n  metaCreate.action(createMetaFile);\n\n  const devMetaChangeId = meta.command(\"ids\");\n  devMetaChangeId.description(\"change all ids in a meta.json file\");\n  devMetaChangeId.action(changeAllIds);\n\n  const commitChanges = commit.command(\"changes\");\n  commitChanges.description(\"return an array of changed files\");\n  commitChanges.argument(\"[commit]\", \"commit to compare to]\");\n  commitChanges.action(commitChangesReturn);\n\n  const dependenciesInstall = dependencies.command(\"install\");\n  dependenciesInstall.description(\"install dependencies\");\n  dependenciesInstall.action(installDependencies);\n}\n",
  "src/lib/command-vault.mjs": "import { $, which, sleep, cd, fs } from 'zx';\nimport {\n  detectScriptsDirectory,\n  recursiveDirectoriesDiscovery,\n  verifyIfMetaJsonExists,\n  environmentSafeguard,\n} from '../utils/divers.mjs';\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// TERRAFORM DEFAULT CONFIG\n////////////////////////////////////////////////////////////////////////////////\n\nconst vaultConfigDefault = {};\n\n////////////////////////////////////////////////////////////////////////////////\n// RUNNING COMMAND LOCATION\n////////////////////////////////////////////////////////////////////////////////\n\nlet currentPath = await detectScriptsDirectory(process.cwd());\n\ncd(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// CURRENT METADATA\n////////////////////////////////////////////////////////////////////////////////\n\nlet metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n////////////////////////////////////////////////////////////////////////////////\n// UTILS\n////////////////////////////////////////////////////////////////////////////////\n\nasync function defineSecretNamespace(target) {\n  const ENV = process.env.ENV;\n  let currentPath = await detectScriptsDirectory(process.cwd());\n  cd(currentPath);\n  let metaConfig = await fs.readJsonSync('meta.json');\n  let { id, scope } = metaConfig;\n  let secretNamespace;\n  if (target) {\n    secretNamespace = `${id}/${target}`;\n  } else if (scope === 'global') {\n    secretNamespace = `${id}/global`;\n  } else {\n    let environment;\n    if (ENV === 'prod') {\n      environment = 'prod';\n    } else if (ENV === 'preview') {\n      environment = 'preview';\n    } else {\n      environment = 'dev';\n    }\n\n    secretNamespace = `${id}/${environment}`;\n  }\n  $.verbose = true;\n  return secretNamespace;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Import json file\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvCertsToVault(data, directoryPath) {\n  if (directoryPath !== undefined) {\n    metaConfig = await verifyIfMetaJsonExists(directoryPath);\n  }\n\n  let secretPath = await defineSecretNamespace();\n\n  secretPath = `${secretPath}/certificats`;\n\n  await $`vault kv put kv/${secretPath} CREDS=${data}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Import json file\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvCertsToLocal(data) {\n  let secretPath = await defineSecretNamespace();\n\n  secretPath = `${secretPath}/certificats`;\n\n  const randomFilename = Math.floor(Math.random() * 1000000);\n\n  try {\n    await $`vault kv get -format=json kv/${secretPath}  > /tmp/env.${randomFilename}.json`;\n\n    $.verbose = true;\n\n    const credsValue = fs.readJSONSync(`/tmp/env.${randomFilename}.json`);\n\n    const { CREDS } = credsValue.data;\n\n    return CREDS;\n  } catch (e) {\n    return '';\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Import .env FILE to remote vault\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvLocalToVault(options) {\n  const { target, envfile } = options;\n\n  let envfilePath = '';\n\n  if (envfile) {\n    envfilePath = envfile;\n  } else {\n    envfilePath = '.env';\n  }\n\n  const envFileRaw = await fs.readFileSync(envfilePath, 'utf8');\n\n  let secretPath = await defineSecretNamespace(target);\n\n  secretPath = `${secretPath}/secrets`;\n\n  $.verbose = true;\n\n  await $`vault kv put kv/${secretPath} CREDS=${envFileRaw}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Export remote vault credentials to gke secret credentials\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvVaultToGkeCredentials() {\n  let secretPath = await defineSecretNamespace();\n\n  secretPath = `${secretPath}/secrets`;\n\n  const randomFilename = Math.floor(Math.random() * 1000000);\n\n  await $`vault kv get -format=json kv/${secretPath}  > /tmp/env.${randomFilename}.json`;\n\n  $.verbose = true;\n\n  const credsValue = fs.readJSONSync(`/tmp/env.${randomFilename}.json`);\n\n  const { CREDS } = credsValue.data;\n\n  return CREDS;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Export remote vault credentials to .env file\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvVaultToLocalEntry(options) {\n  const { all } = options;\n\n  if (all) {\n    await vaultKvVaultToLocalAll();\n  } else {\n    await vaultKvVaultToLocalUnit();\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Export all proeject vault secrets to .env file\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvVaultToLocalAll() {\n  let metaConfig = await fs.readJsonSync('meta.json');\n  let allDirectories = await recursiveDirectoriesDiscovery(\n    `${process.env.SRC}`\n  );\n\n  allDirectories.push(`${process.env.SRC}`);\n\n  for (let directory of allDirectories) {\n    const meta = await verifyIfMetaJsonExists(directory);\n\n    if (meta.secrets) {\n      metaConfig = meta;\n      currentPath = directory;\n      sleep(2000);\n      await vaultKvVaultToLocalUnit(currentPath);\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Export remote vault credentials to .env file\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function vaultKvVaultToLocalUnit(currentPathNew) {\n  let currentPath = await detectScriptsDirectory(process.cwd());\n\n  if (currentPathNew !== undefined) {\n    currentPath = currentPathNew;\n  }\n\n  cd(currentPath);\n\n  let metaConfig = await fs.readJsonSync('meta.json');\n\n  let { vault } = metaConfig;\n\n  if (vault !== undefined) {\n    let { ignoreEnv } = vault;\n    if (ignoreEnv) {\n      const environment = process.env.ENV;\n\n      // verify if environment is included in ignoreEnv array\n      if (ignoreEnv.includes(environment)) {\n        return;\n      }\n    }\n  }\n\n  let secretPath = await defineSecretNamespace();\n\n  secretPath = `${secretPath}/secrets`;\n\n  // generate a random integer number\n\n  const randomFilename = Math.floor(Math.random() * 1000000);\n\n  await $`vault kv get -format=json kv/${secretPath}  > /tmp/env.${randomFilename}.json`;\n\n  const credsValue = await fs.readJSONSync(`/tmp/env.${randomFilename}.json`);\n\n  const { CREDS } = credsValue.data;\n\n  // if .env file exists, create a backup\n  if (await fs.existsSync('.env')) {\n    await fs.copyFileSync('.env', '.env.backup');\n  }\n\n  await fs.writeFileSync('.env', CREDS, 'utf8');\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\n// commands\n// create/update a vault secret\n// actions\n\nexport default async function vault(program) {\n  const vault = program.command('vault');\n  vault.description('manage project secrets');\n  const vaultKv = vault.command('kv');\n  vaultKv.description('manage key-value pairs');\n\n  const vaultKvImport = vaultKv.command('import');\n  const vaultKvExport = vaultKv.command('export');\n\n  vaultKvImport\n    .description('from .env to remote vault')\n    .action(vaultKvLocalToVault)\n    .option('--envfile <path>', 'path to .env file')\n    .option('--target <environment>', 'environment target');\n\n  vaultKvExport\n    .description('from remote vault to .env')\n    .option('--all', 'export all project secrets')\n    .action(vaultKvVaultToLocalEntry);\n}\n",
  "src/lib/command-vercel.mjs": "import { $, which, sleep, cd, fs } from \"zx\";\nimport core from \"@actions/core\";\nimport {\n  detectScriptsDirectory,\n  verifyIfMetaJsonExists,\n} from \"../utils/divers.mjs\";\n\nimport { envDevcontainer } from \"../main.mjs\";\n\n////////////////////////////////////////////////////////////////////////////////\n// MUTE BY DEFAULT\n////////////////////////////////////////////////////////////////////////////////\n\n$.verbose = false;\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\nconst VERCEL_TOKEN = process.env.VERCEL_TOKEN || process.env.RUN_VERCEL_TOKEN;\n\n////////////////////////////////////////////////////////////////////////////////\n// LOGS\n////////////////////////////////////////////////////////////////////////////////\n\nasync function vercelLogsDeployment(deploymentId) {\n  $.verbose = true;\n\n  await $`vercel logs ${deploymentId} --token ${VERCEL_TOKEN} --debug -f`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// LIST\n////////////////////////////////////////////////////////////////////////////////\n\nasync function vercelListDeployments() {\n  $.verbose = true;\n\n  await $`vercel list --token ${VERCEL_TOKEN}`;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// MAIN ENTRY POINT\n////////////////////////////////////////////////////////////////////////////////\n\nexport default async function vercel(program) {\n  const vercel = program.command(\"vercel\");\n  vercel.description(\"manage vercel deployments\");\n\n  const vercelList = vercel.command(\"list\");\n\n  vercelList.description(\"list all deployments\").action(vercelListDeployments);\n\n  const vercelLogs = vercel.command(\"logs\");\n\n  vercelLogs\n    .description(\"get logs for a deployment\")\n    .argument(\"<deploymentId>\", \"deployment id\")\n    .action(vercelLogsDeployment);\n}\n",
  "src/utils/divers.mjs": "import { $, sleep, cd, fs, echo } from 'zx';\nimport { config } from 'dotenv';\n\n////////////////////////////////////////////////////////////////////////////////\n// CONSTANTS\n////////////////////////////////////////////////////////////////////////////////\n\n////////////////////////////////////////////////////////////////////////////////\n// DETECT SCRIPS DIRECTORY\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function detectScriptsDirectory(currentPath) {\n  // verify if the current path ends with scripts\n\n  if (currentPath.includes('scripts')) {\n    // remove /scripts from the path\n    currentPath = currentPath.replace('/scripts', '');\n    return currentPath;\n  }\n\n  return currentPath;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// GET PROJECT TYPE\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function verifyIfProjectCore() {\n  cd(process.env.SRC);\n\n  const metaConfig = await fs.readJsonSync('meta.json');\n  const { type, name } = metaConfig;\n\n  if (type === 'project') {\n    if (name === 'core') {\n      return true;\n    }\n  }\n  return false;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RETURN ALL THE DIRECTORIES IN A PATH\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function getDirectories(path) {\n  const directoriesWithFiles = await fs.readdir(`${path}`, {\n    withFileTypes: true,\n  });\n\n  const directories = directoriesWithFiles\n    .filter((dirent) => dirent.isDirectory())\n    .filter((dirent) => dirent.name !== 'node_modules')\n    .filter((dirent) => dirent.name !== '.git')\n    .filter((dirent) => dirent.name !== 'migrations')\n    .map((dirent) => dirent.name);\n\n  return directories;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// DISCOVER ALL THE DIRECTORIES PATH  IN THE PROJECT (RECURSIVE)\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function recursiveDirectoriesDiscovery(path) {\n  const directories = await getDirectories(path);\n\n  let directoriesPath = [];\n\n  for (let directory of directories) {\n    directoriesPath.push(`${path}/${directory}`);\n    directoriesPath = directoriesPath.concat(\n      await recursiveDirectoriesDiscovery(`${path}/${directory}`)\n    );\n  }\n\n  return directoriesPath;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// VERIFY IF THERE IS A META.JSON FILE IN THE CURRENT PATH\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function verifyIfMetaJsonExists(path) {\n  try {\n    await fs.access(`${path}/meta.json`);\n\n    return fs.readJsonSync(`${path}/meta.json`);\n  } catch (error) {\n    return false;\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RETURN ALL FOLDER PATH THAT MATCHES THE META.JSON FILE CONDITION\n// document this function\n// @param {string} property - the property to match\n// @param {string} value - the value to match (optional)\n// return {array} - an array of path that matches the condition\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function withMetaMatching({ property, value, path }) {\n  let directoryEntryPath = path || process.env.SRC;\n\n  const allDirectories = await recursiveDirectoriesDiscovery(\n    directoryEntryPath\n  );\n\n  let directories = [];\n\n  for (let directory of allDirectories) {\n    const metaConfig = await verifyIfMetaJsonExists(directory);\n\n    if (metaConfig) {\n      let metaConfigProperty;\n\n      if (property.includes('.')) {\n        const propertyArray = property.split('.');\n\n        metaConfigProperty = metaConfig;\n\n        for (let propertyComponent of propertyArray) {\n          metaConfigProperty = metaConfigProperty[propertyComponent];\n\n          if (metaConfigProperty === undefined) {\n            break;\n          }\n        }\n      } else {\n        metaConfigProperty = metaConfig[property];\n      }\n\n      if (value === undefined && metaConfigProperty) {\n        directories.push({ directory, config: metaConfig });\n      } else if (metaConfigProperty === value && metaConfigProperty) {\n        directories.push({ directory, config: metaConfig });\n      }\n    }\n  }\n\n  return directories;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// setSecretsUptoProject\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function setSecretsUptoProject(path) {\n  // print all the parent directories\n  // example: if path == /home/ghostmind/dev/src/projects/ghostmind\n  // print: /home/ghostmind/dev/src/projects/ghostmind\n  // print: /home/ghostmind/dev/src/projects\n  // print: /home/ghostmind/dev/src\n  // print: /home/ghostmind/dev\n  // print: /home/ghostmind\n  // print: /home\n  // print: /\n\n  const directories = path.split('/');\n  let directoriesPath = [];\n\n  for (let i = directories.length; i > 0; i--) {\n    directoriesPath.push(directories.slice(0, i).join('/'));\n  }\n\n  for (let directory of directoriesPath) {\n    let metaConfig = await verifyIfMetaJsonExists(directory);\n\n    if (metaConfig) {\n      if (metaConfig.secrets) {\n        config({ path: `${directory}/.env` });\n      }\n      if (metaConfig.type === 'project') {\n        return;\n      }\n    }\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// ENVIRONMENT SAFEGUARD\n////////////////////////////////////////////////////////////////////////////////\n\nexport async function environmentSafeguard(currentPath) {\n  const metaConfig = await verifyIfMetaJsonExists(currentPath);\n\n  let directoryNoMatchEnv = [];\n\n  for (const directoryObject of directoriesBindToEnv) {\n    const { directory } = directoryObject;\n    config({ path: `${directory}/.env`, override: true });\n\n    if (process.env.ENV !== process.env.ENVIRONMENT) {\n      directoryNoMatchEnv.push(directory);\n    }\n  }\n\n  if (directoryNoMatchEnv.length > 0) {\n    const prompt = inquirer.createPromptModule();\n\n    const answer = await prompt({\n      type: 'confirm',\n      name: 'answer',\n      message:\n        '\\n' +\n        `Some directories are bind to a different environment than ${process.env.ENV}` +\n        `\\n` +\n        `\\n${directoryNoMatchEnv.join('\\n')}` +\n        `\\n` +\n        `\\nDo you want to continue?`,\n    });\n\n    if (!answer) {\n      process.exit(1);\n    }\n  }\n}\n"
}